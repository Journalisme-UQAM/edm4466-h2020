# 09 - TAL 1

## 5 mars 2020

Parmi les autres applications de la programmation qui peuvent être pertinentes pour les journalistes, on trouve ce qu'on appelle le [**traitement automatique du langage naturel**](https://fr.wikipedia.org/wiki/Traitement_automatique_du_langage_naturel) \(TALN, qu'on raccourcit aussi à TAL\). Vous rencontrerez, en anglais, l'expression _NLP_ pour _Natural Language Processing_.

Il arrive souvent, en journalisme, qu'on veuille extraire du sens d'un important corpus de texte \(des articles ou chroniques, des transcriptions de débats parlementaires, des tweets, etc.\). C'est possible, grâce au TAL.

Mais avant de procéder, on va faire, dans ce premier cours, un peu de théorie sur cette discipline en abordant les différentes étapes de **pré-traitement** qu'on peut faire subir à un corpus de textes et en définissant certaines notions telles que :

* l'analyse lexicale \(ou _tokenization_\)
* la lemmatisation \(ou _lemmatization_\)
* la racinisation \(ou _stemming_\)
* l'étiquettage morpho-syntaxique \(ou _part-of-speech tagging_\)
* les mots-vides \(ou _stopwords_\)
* les entités nommées \(ou _named entities_\)
* l'analyse de sentiment \(ou _sentiment analysis_\)
* la modélisation thématique \(ou _topic modeling_\)
* la reconnaissance optique des caractères \(ou _OCR_\)

On va aller au-delà du simple nuage de mots. Car comme le disait le linguiste britannique John R. Firth, un mot seul n'est rien sans son contexte. Les mots seuls peuvent avoir plusieurs sens. C'est en regardant quels sont les mots qui se trouvent avant et après qu'ils prennent tout leur sens. 

![John Rupert Firth \(1890-1960\)](../.gitbook/assets/firth.jpg)

> _« You shall know a word by the company it keeps »_
>
> -- John Rupert Firth \(1890-1960\)

La semaine prochaine, nous allons plonger dans le concret. Mais auparavant, il faudra installer deux choses. Dans une fenêtre de terminal de Visual Studio, entrez la commande suivante :

```text
$ conda install -c conda-forge spacy
```

Vous allez peut-être voir le message suivant:

```text
The following packages will be DOWNGRADED:

  anaconda                                   2019.07-py37_0 --> custom-py37_1


Proceed ([y]/n)? 
```

À la question `Proceed ([y]/n)?` répondez `y`.

Une fois spaCy installé, vous devrez y ajouter quelque chose qui lui permettra d'analyser du texte en français. Cette chose est un «CNN». Et ça n'a rien à voir avec le _Cable News Network_.

Il s'agit plutôt d'un _Convolutional Neural Network_, un [**réseau neuronal convolutif**](https://fr.wikipedia.org/wiki/R%C3%A9seau_neuronal_convolutif), qui est en fait un modèle pré-entraîné avec du texte français, essentiellement extrait de Wikipédia, pour reconnaître les caractéristiques des mots et des phrases que vous soumettrez à spaCy. 

```text
$ python -m spacy download fr_core_news_md
```

On va donc, dans cette partie du cours, se servir d'une forme d'intelligence artificielle pour faire nos analyses de textes. Mais attention. Le modèle n'est pas parfait, comme vous pouvez le constater sur sa [description](https://github.com/explosion/spacy-models/releases//tag/fr_core_news_md-2.2.5). N'oubliez jamais que les outils informatiques ont leurs limites.

